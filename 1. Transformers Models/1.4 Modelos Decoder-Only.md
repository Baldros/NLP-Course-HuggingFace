# Modelos Decoder-Only:
Os modelos Decoder-Only referem-se a uma categoria específica de arquiteturas Transformer que utilizam exclusivamente a parte do decodificador do modelo. Ao contrário dos modelos Encoder-Only, esses modelos são projetados para operar sequencialmente, permitindo que as camadas de atenção acessem apenas as palavras anteriores em uma sentença durante cada estágio de geração. Esses modelos são comumente denominados modelos autoregressivos.

Durante o pré-treinamento, a ênfase dos modelos de decodificador está na previsão da próxima palavra em uma sequência. Isso os torna particularmente adequados para tarefas que envolvem a geração de texto, onde a capacidade de construir continuamente uma sequência coerente é crucial.
