{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "y9mJIvqELoh7",
        "ag34H6B7MHmh",
        "yo7OA0piT3G1",
        "5QlotA27V96R",
        "uCff9du2ffcy"
      ],
      "authorship_tag": "ABX9TyNN5oyDdrzANUiv+2RpuNMF",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Baldros/NLP-Course-HuggingFace/blob/main/2.1%20Behind_the_pipeline.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Apresenta√ß√£o:\n",
        "\n",
        "    Aqui aprenderemos um pouco sobre a constru√ß√£o do m√©todo Pipeline da\n",
        "    biblioteca transformers. O curso apresenta a explica√ß√£o para o pytorch\n",
        "    e para o tensorflow. Aqui constar√° a explica√ß√£o para ambas as bibliotecas.\n",
        "\n",
        "    Nesse inicio, a difer√™ncia √© t√£o sutil, que d√° para seguir de uma forma\n",
        "    geral para ambos os casos at√© o final desse notebook."
      ],
      "metadata": {
        "id": "kSe9wJAcKeuT"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Por de tr√°s do pipeline:\n",
        "\n",
        "    Vamos come√ßar com um exemplo completo, ando uma\n",
        "    olhada no que aconteceu nos bastidores quando\n",
        "    executamos o seguinte c√≥digo no Cap√≠tulo 1:"
      ],
      "metadata": {
        "id": "y9mJIvqELoh7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Importando a API pipeline:\n",
        "from transformers import pipeline"
      ],
      "metadata": {
        "id": "PtNg5_d6Kqks"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Exemplo utilizado:\n",
        "classifier = pipeline(\"sentiment-analysis\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mtagKhYNMDC4",
        "outputId": "95fdc1eb-6a13-4265-dd83-b44984bbe837"
      },
      "execution_count": 105,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "No model was supplied, defaulted to distilbert/distilbert-base-uncased-finetuned-sst-2-english and revision af0f99b (https://huggingface.co/distilbert/distilbert-base-uncased-finetuned-sst-2-english).\n",
            "Using a pipeline without specifying a model name and revision in production is not recommended.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "classifier(\n",
        "    [\n",
        "        \"I've been waiting for a HuggingFace course my whole life.\",\n",
        "        \"I hate this so much!\",\n",
        "    ]\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4Z73wASkkzh_",
        "outputId": "ecd5696d-3d63-4e01-f8ba-8d82316c4608"
      },
      "execution_count": 106,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[{'label': 'POSITIVE', 'score': 0.9598048329353333},\n",
              " {'label': 'NEGATIVE', 'score': 0.9994558691978455}]"
            ]
          },
          "metadata": {},
          "execution_count": 106
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "    Como j√° vimos no Cap√≠tulo 1, esse pipeline agrupa as tr√™s\n",
        "    principais etapas: pr√©-processamento, passagem das entradas\n",
        "    pelo modelo e p√≥s-processamento. No contexto de NLP, podemos\n",
        "    renomear essas tr√™s etapas como:\n",
        "    \n",
        "![image.png](data:image/png;base64,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)"
      ],
      "metadata": {
        "id": "TRPwENNRMONj"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Pr√©-processamento com um tokenizador:\n",
        "\n",
        "    Assim como outras redes neurais, os modelos Transformer n√£o podem\n",
        "    processar texto bruto diretamente (n√£o podemos esquecer que computadores\n",
        "    s√£o m√°quinas de fazer conta n√©). Portanto, a primeira etapa de nosso\n",
        "    pipeline √© converter as entradas de texto em n√∫meros que o modelo\n",
        "    possa entender. Para fazer isso, usamos um tokenizador, que ser√°\n",
        "    respons√°vel por:\n",
        "\n",
        "    1. Dividir a entrada em palavras, subpalavras ou s√≠mbolos (como pontua√ß√£o) chamados de tokens;\n",
        "    2. Mapear cada token para um inteiro;\n",
        "    3. Adicionar entradas adicionais que podem ser √∫teis para o modelo.\n",
        "\n",
        "    Todo esse pr√©-processamento precisa ser feito exatamente da mesma\n",
        "    maneira que durante o pr√©-treinamento do modelo. Portanto, primeiro\n",
        "    precisamos baixar essas informa√ß√µes do Model Hub. Para fazer isso,\n",
        "    usamos a classe AutoTokenizer e seu m√©todo from_pretrained(). Usando\n",
        "    o nome do ponto de verifica√ß√£o (checkpoint) do nosso modelo, ele\n",
        "    buscar√° automaticamente os dados associados ao tokenizador do modelo\n",
        "    e far√° cache deles (portanto, s√≥ ser√° baixado na primeira vez que voc√™\n",
        "    executar o c√≥digo abaixo).\n",
        "\n",
        "Nota:\n",
        "\n",
        "    Apesar de n√£o ficar bem explicado, eu gosto de ressaltar que tokenizadores\n",
        "    tamb√©m s√£o redes neurais, basicamente, tudo aqui √© rede neural, tanto\n",
        "    o modelo em si, quanto os outros processos que alimentam o modelo. Eu\n",
        "    gosto de ressaltar esse ponto, porque, principalmente para os iniciantes,\n",
        "    isso n√£o fica muito claro, essa parte passa-se meio batido.\n",
        "\n",
        "Dito isso:\n",
        "\n",
        "    Como o ponto de verifica√ß√£o padr√£o do pipeline de an√°lise de sentimento\n",
        "    √© distilbert-base-uncased-finetuned-sst-2-english, executamos o seguinte:\n",
        "\n",
        "Modelo: ttps://huggingface.co/distilbert/distilbert-base-uncased-finetuned-sst-2-english\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "ag34H6B7MHmh"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Nota:\n",
        "\n",
        "    A partir desse ponto come√ßaram a aparecer as diferen√ßas entre\n",
        "    se utilizar Pytorch ou Tensorflow, como dito na aprensenta√ß√£o,\n",
        "    irei elaborar estudar aqui as duas possibilidade. √â bem simples,\n",
        "    no nivel que estamos estudando, n√£o h√° muita diferen√ßa."
      ],
      "metadata": {
        "id": "fuBObDxbPQKI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Com o Pytorch**"
      ],
      "metadata": {
        "id": "Wfn9xBn-PkXC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Importando Tokenizador:\n",
        "from transformers import AutoTokenizer"
      ],
      "metadata": {
        "id": "gCUgz5m0Pta5"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Definindo o modelo a ser utilizado - A arquitetura e os pesos:\n",
        "checkpoint = \"distilbert-base-uncased-finetuned-sst-2-english\""
      ],
      "metadata": {
        "id": "7oFWNQbeVsk4"
      },
      "execution_count": 48,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Instanciando o modelo:\n",
        "tokenizer = AutoTokenizer.from_pretrained(checkpoint)"
      ],
      "metadata": {
        "id": "4ogzWfckN46L"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "    Depois de obtermos o tokenizador, podemos passar diretamente nossas\n",
        "    senten√ßas para ele e receberemos de volta um dicion√°rio pronto para\n",
        "    alimentar nosso modelo! A √∫nica coisa que resta fazer √© converter a\n",
        "    lista de IDs de entrada em tensores.\n",
        "\n",
        "    Para especificar o tipo de tensores que queremos receber de volta\n",
        "    (PyTorch, TensorFlow ou NumPy puro), usamos o argumento return_tensors:"
      ],
      "metadata": {
        "id": "RXCX1R4OP6tp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Tokenizando:\n",
        "raw_inputs = [\n",
        "    \"I've been waiting for a HuggingFace course my whole life.\",\n",
        "    \"I hate this so much!\",\n",
        "]\n",
        "# Realizando a infer√™ncia\n",
        "inputs_torch = tokenizer(raw_inputs, padding=True, truncation=True, return_tensors=\"pt\") #pt == Pytorch"
      ],
      "metadata": {
        "id": "zxgtTMJEP0YI"
      },
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Como o retorno √© um dicion√°rio:\n",
        "print(inputs_torch.keys())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vb--geG0Qseg",
        "outputId": "5e041867-7060-492d-8aa3-f47a11dfc8d0"
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "dict_keys(['input_ids', 'attention_mask'])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Retornando os elementos do Dicion√°rio:\n",
        "print(inputs_torch['input_ids'])\n",
        "print(inputs_torch['attention_mask'])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KuR_eefcQxwL",
        "outputId": "0c3827ab-5559-4e79-b52f-a999e7e1274e"
      },
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[  101,  1045,  1005,  2310,  2042,  3403,  2005,  1037, 17662, 12172,\n",
            "          2607,  2026,  2878,  2166,  1012,   102],\n",
            "        [  101,  1045,  5223,  2023,  2061,  2172,   999,   102,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0]])\n",
            "tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
            "        [1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Realizando a infer√™ncia**\n",
        "\n",
        "    Realizar a infer√™ncia do modelo refere-se ao processo de usar um\n",
        "    modelo treinado para fazer previs√µes ou gerar sa√≠das com base em\n",
        "    dados de entrada. Essa √© uma nomenclatura espec√≠fica para chamar\n",
        "    as predi√ß√µes feitas por modelos pr√©-treinados.\n",
        "    \n",
        "    Essa linguagem serve para qualquer tipo de biblioteca que se esteja\n",
        "    utilizando como suporte para a API do transformer."
      ],
      "metadata": {
        "id": "vHN5ZVPKXTTb"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Com o Tensorflow**"
      ],
      "metadata": {
        "id": "tQmHIQuaSUi6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "raw_inputs = [\n",
        "    \"I've been waiting for a HuggingFace course my whole life.\",\n",
        "    \"I hate this so much!\",\n",
        "]\n",
        "\n",
        "# Realizando a infer√™ncia\n",
        "inputs_tf = tokenizer(raw_inputs, padding=True, truncation=True, return_tensors=\"tf\") # tf == tensorflow"
      ],
      "metadata": {
        "id": "S6jUTiaFSXJs"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Como o retorno √© um dicion√°rio:\n",
        "print(inputs_tf.keys())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "s_kX8j_NSrGM",
        "outputId": "1a9e186a-772f-45e2-d067-9be196b7714b"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "dict_keys(['input_ids', 'attention_mask'])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Retornando os elementos do Dicion√°rio:\n",
        "print(inputs_tf['input_ids'])\n",
        "print(inputs_tf['attention_mask'])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c17Qr5bgStJC",
        "outputId": "77572c0b-8395-4728-a33f-0b054d4b4d3d"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tf.Tensor(\n",
            "[[  101  1045  1005  2310  2042  3403  2005  1037 17662 12172  2607  2026\n",
            "   2878  2166  1012   102]\n",
            " [  101  1045  5223  2023  2061  2172   999   102     0     0     0     0\n",
            "      0     0     0     0]], shape=(2, 16), dtype=int32)\n",
            "tf.Tensor(\n",
            "[[1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]\n",
            " [1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0]], shape=(2, 16), dtype=int32)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Onde, para ambos os casos:**\n",
        "\n",
        "    1. 'input_ids': S√£o os identificadores num√©ricos √∫nicos associados\n",
        "    a cada token no vocabul√°rio do modelo. Cada n√∫mero inteiro representa\n",
        "    um token espec√≠fico. No exemplo fornecido, os n√∫meros epresentam os\n",
        "    tokens em ingl√™s correspondentes √†s palavras nas frases originais.\n",
        "    O token especial [CLS] (101) √© adicionado no in√≠cio de cada sequ√™ncia,\n",
        "    e [SEP] (102) √© adicionado ao final. Tokens adicionais s√£o preenchidos\n",
        "    com zeros √† direita para alinhar as sequ√™ncias, devido ao par√¢metro\n",
        "    padding=True.\n",
        "\n",
        "    2. 'attention_mask': S√£o os elementos da sequ√™ncia s√£o tokens reais\n",
        "    e quais s√£o tokens de preenchimento. Um valor de 1 indica que o token\n",
        "    na posi√ß√£o correspondente em 'input_ids' √© um token real, enquanto um\n",
        "    valor de 0 indica que √© um token de preenchimento. Isso √© √∫til para\n",
        "    garantir que o modelo leve em considera√ß√£o apenas os tokens relevantes\n",
        "    durante o processamento."
      ],
      "metadata": {
        "id": "ebOzPaVVRRpM"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "    Note que a diferen√ßa de se utilizar pytorch para tensorflow\n",
        "    √© realmente muito pouca. O tensorflow da um pouquinho mais\n",
        "    de informa√ß√£o mais √© bobagem."
      ],
      "metadata": {
        "id": "W8xM-t1nS_Nt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Tensorflow:\n",
        "inputs_tf"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hzo9FNkbS87W",
        "outputId": "85abd657-9384-4d1f-db68-2662df970f76"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'input_ids': <tf.Tensor: shape=(2, 16), dtype=int32, numpy=\n",
              "array([[  101,  1045,  1005,  2310,  2042,  3403,  2005,  1037, 17662,\n",
              "        12172,  2607,  2026,  2878,  2166,  1012,   102],\n",
              "       [  101,  1045,  5223,  2023,  2061,  2172,   999,   102,     0,\n",
              "            0,     0,     0,     0,     0,     0,     0]], dtype=int32)>, 'attention_mask': <tf.Tensor: shape=(2, 16), dtype=int32, numpy=\n",
              "array([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
              "       [1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0]], dtype=int32)>}"
            ]
          },
          "metadata": {},
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Pytorch\n",
        "inputs_torch"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3UkRBGZwQg05",
        "outputId": "cde09a52-a36d-481e-d709-2da55240d27f"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'input_ids': tensor([[  101,  1045,  1005,  2310,  2042,  3403,  2005,  1037, 17662, 12172,\n",
              "          2607,  2026,  2878,  2166,  1012,   102],\n",
              "        [  101,  1045,  5223,  2023,  2061,  2172,   999,   102,     0,     0,\n",
              "             0,     0,     0,     0,     0,     0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
              "        [1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0]])}"
            ]
          },
          "metadata": {},
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Tensores**\n",
        "\n",
        "    Voc√™ pode usar ü§ó Transformers sem se preocupar com qual framework de\n",
        "    ML est√° sendo usado como backend; pode ser PyTorch, TensorFlow ou Flax\n",
        "    para alguns modelos. No entanto, modelos Transformer aceitam apenas\n",
        "    tensores como entrada. Se esta for a primeira vez que voc√™ ouve falar\n",
        "    sobre tensores, pode pensar neles como arrays NumPy. Um array NumPy pode\n",
        "    ser um escalar (0D), um vetor (1D), uma matriz (2D) ou ter mais dimens√µes.\n",
        "    como tensores (3D). Efetivamente, √© um tensor; os tensores de outros\n",
        "    frameworks de ML se comportam de maneira semelhante e geralmente s√£o t√£o\n",
        "    simples de instanciar quanto arrays NumPy.\n",
        "\n",
        "Nota:\n",
        "\n",
        "    A ideia de tensor da Matem√°tica √© um pouco diferente da ideia de tensor\n",
        "    de Machine Learning, n√£o vou aqui abordar muito esse tema, at√© porque\n",
        "    nem eu entendo exatamente bem a diferen√ßa entre ambos. Basta dizer que\n",
        "    aqui estamos nos baseando na defini√ß√£o de tensores utilizadas em ML."
      ],
      "metadata": {
        "id": "hjUjmV3PTZAW"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Passando pelo modelo\n",
        "\n",
        "    Aqui de fato a aparecer umas diferen√ßas mais profundas entre\n",
        "    a utiliza√ß√£o de bibliotecas diferentes de ML. De fato aqui,\n",
        "    at√© o modelo √© diferente. Dito isso, Podemos baixar nosso modelo\n",
        "    pr√©-treinado da mesma forma que fizemos com nosso tokenizador.\n",
        "    ü§ó Transformers fornece uma classe AutoModel/TFAutoModel que\n",
        "    tamb√©m possui um m√©todo from_pretrained:"
      ],
      "metadata": {
        "id": "yo7OA0piT3G1"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Com o Pytorch**"
      ],
      "metadata": {
        "id": "gYdfYC4IUScE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# API para o Pytorch:\n",
        "from transformers import AutoModel"
      ],
      "metadata": {
        "id": "3fxYtG9eRAhY"
      },
      "execution_count": 52,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Instanciando modelo:\n",
        "model_torch = AutoModel.from_pretrained(checkpoint)"
      ],
      "metadata": {
        "id": "upv1V1TJUY7a"
      },
      "execution_count": 57,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Com o Tensorflow**"
      ],
      "metadata": {
        "id": "EkvPtQMlVadw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# API para o Tensorflow:\n",
        "from transformers import TFAutoModel"
      ],
      "metadata": {
        "id": "3kHKOB6yVPcz"
      },
      "execution_count": 54,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Instanciando o modelo:\n",
        "model_tf = TFAutoModel.from_pretrained(checkpoint)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4BhCzqUpVmG8",
        "outputId": "282e64b4-1e26-46b0-bf37-df0b13f767e2"
      },
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of the PyTorch model were not used when initializing the TF 2.0 model TFDistilBertModel: ['pre_classifier.weight', 'classifier.bias', 'classifier.weight', 'pre_classifier.bias']\n",
            "- This IS expected if you are initializing TFDistilBertModel from a PyTorch model trained on another task or with another architecture (e.g. initializing a TFBertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing TFDistilBertModel from a PyTorch model that you expect to be exactly identical (e.g. initializing a TFBertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "All the weights of TFDistilBertModel were initialized from the PyTorch model.\n",
            "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFDistilBertModel for predictions without further training.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Utilizando o mesmo conjunto de pesos:\n",
        "\n",
        "    Neste trecho de c√≥digo, baixamos o mesmo ponto de verifica√ß√£o (checkpoint)\n",
        "    ou seja, o nosso conjunto de pesos que usamos em nosso pipeline anterior\n",
        "    (ele deveria ter sido armazenado em cache) e instanciamos um modelo com ele.\n",
        "\n",
        "    Esta arquitetura cont√©m apenas o m√≥dulo Transformer base: dadas algumas\n",
        "    entradas, ela gera o que chamaremos de estados ocultos (hidden states),\n",
        "    tamb√©m conhecidos como caracter√≠sticas (features). Para cada entrada do\n",
        "    modelo, recuperaremos um vetor de alta dimens√£o representando a compreens√£o\n",
        "    contextual dessa entrada pelo modelo Transformer.\n",
        "\n",
        "    Se isso n√£o fizer sentido, n√£o se preocupe. Explicaremos tudo mais tarde.\n",
        "\n",
        "    Embora esses estados ocultos possam ser √∫teis por si s√≥, geralmente s√£o\n",
        "    entradas para outra parte do modelo, conhecida como a cabe√ßa (head).\n",
        "    No Cap√≠tulo 1, as diferentes tarefas poderiam ter sido realizadas com\n",
        "    a mesma arquitetura, mas cada uma dessas tarefas ter√° uma cabe√ßa (head)\n",
        "    diferente associada.\n",
        "    \n",
        "Um vetor de alta dimens√£o?\n",
        "\n",
        "    O vetor gerado pelo m√≥dulo Transformer geralmente √© grande. Geralmente,\n",
        "    ele tem tr√™s dimens√µes, por isso ele √© e precisa ser um tensor:\n",
        "\n",
        "    1. Tamanho do lote (batch size): O n√∫mero de sequ√™ncias processadas\n",
        "    de uma vez (2 em nosso exemplo);\n",
        "    2. Comprimento da sequ√™ncia (sequence length): O comprimento da\n",
        "    representa√ß√£o num√©rica da sequ√™ncia (16 em nosso exemplo);\n",
        "    3. Tamanho oculto (hidden size): A dimens√£o do vetor de cada entrada\n",
        "    do modelo.\n",
        "\n",
        "    √â chamado de \"alta dimens√£o\" por causa do √∫ltimo valor. O tamanho\n",
        "    oculto pode ser muito grande (768 √© comum para modelos menores, e\n",
        "    em modelos maiores isso pode chegar a 3072 ou mais).\n",
        "\n",
        "    Podemos ver isso se alimentarmos as entradas que pr√©-processamos em\n",
        "    nosso modelo:"
      ],
      "metadata": {
        "id": "HAEuoAZcX39L"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Com o Pytorch**"
      ],
      "metadata": {
        "id": "T1oEmeX5Zoxy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Realizando a infer√™ncia do modelo\n",
        "outputs_torch = model_torch(**inputs_torch)\n",
        "print(outputs_torch.last_hidden_state.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "W12Pe9cEUeQB",
        "outputId": "2a726af5-a8fb-43a9-d23d-9c2c9e39fdb9"
      },
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([2, 16, 768])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "    Note que aqui tem uma diferen√ßa... Porque no pytorch entra\n",
        "    esse elemento ** no par√¢metro. O uso do duplo asterisco (**)\n",
        "    em Python √© conhecido como \"desempacotamento de dicion√°rio\" ou\n",
        "    \"argumentos de palavras-chave arbitr√°rios\". Ele √© usado para\n",
        "    passar um dicion√°rio como argumentos de palavra-chave para uma\n",
        "    fun√ß√£o."
      ],
      "metadata": {
        "id": "9shbGnmIWBJy"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Com o Tensorflow**"
      ],
      "metadata": {
        "id": "sUVnt8_UZq5Z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Realizando a infer√™ncia do modelo\n",
        "outputs_tf = model_tf(inputs_tf)\n",
        "print(outputs_tf.last_hidden_state.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ANLHbA2VVorx",
        "outputId": "19477455-2487-49ff-c113-3ee9e5e60cad"
      },
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(2, 16, 768)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "    Note que no caso do tensorflow, n√£o h√° a necessidade de\n",
        "    se \"desempacotar o dicion√°rio\"."
      ],
      "metadata": {
        "id": "2BaI1MdlWfsf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Nota:\n",
        "\n",
        "    Observe que as sa√≠das dos modelos ü§ó Transformers se comportam como\n",
        "    namedtuples ou dicion√°rios. Voc√™ pode acessar os elementos por atributos\n",
        "    (como fizemos) ou por chave (outputs[\"last_hidden_state\"]), ou at√© mesmo\n",
        "    por √≠ndice se souber exatamente onde est√° o que est√° procurando (outputs[0])."
      ],
      "metadata": {
        "id": "qXCxZxfTbAsk"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Model Heads: Entendendo os n√∫meros\n",
        "\n",
        "    As cabe√ßas do modelo (Model Heads) recebem o vetor de alta dimens√£o\n",
        "    dos estados ocultos como entrada e os projetam em uma dimens√£o diferente.\n",
        "    Geralmente, s√£o compostas por uma ou algumas camadas lineares:\n",
        "\n",
        "![image.png](data:image/png;base64,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)"
      ],
      "metadata": {
        "id": "5QlotA27V96R"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "    A sa√≠da do modelo Transformer √© enviada diretamente para a cabe√ßa do\n",
        "    modelo (head) para ser processada.\n",
        "\n",
        "    Neste diagrama, o modelo √© representado por sua camada de embeddings e\n",
        "    pelas camadas subsequentes. A camada de embeddings converte cada ID de\n",
        "    entrada na entrada tokenizada em um vetor que representa o token associado.\n",
        "    As camadas subsequentes manipulam esses vetores usando o mecanismo de\n",
        "    aten√ß√£o (self-attention) para produzir a representa√ß√£o final das senten√ßas.\n",
        "\n",
        "    Existem muitas arquiteturas diferentes dispon√≠veis em ü§ó Transformers,\n",
        "    cada uma projetada para enfrentar uma tarefa espec√≠fica. Aqui est√° uma\n",
        "    lista n√£o exaustiva:\n",
        "\n",
        "**Model (recupera os hidden states)**\n",
        "\n",
        "    Esta classe √© geralmente utilizada para recuperar os estados ocultos\n",
        "    de um modelo Transformer, ou seja, as representa√ß√µes intermedi√°rias\n",
        "    geradas durante o processamento de uma sequ√™ncia de entrada. √â √∫til\n",
        "    para an√°lises mais avan√ßadas e tarefas personalizadas que podem\n",
        "    exigir acesso a esses estados.\n",
        "\n",
        "**ForCausalLM**\n",
        "\n",
        "    Projetado para modelos de linguagem causais, este tipo de classe √©\n",
        "    usado para tarefas em que a predi√ß√£o de uma palavra depende apenas\n",
        "    das palavras anteriores na sequ√™ncia. Geralmente, √© √∫til em gera√ß√£o\n",
        "    de texto onde a ordem das palavras √© crucial.\n",
        "\n",
        "**ForMaskedLM**\n",
        "\n",
        "    Essa classe √© espec√≠fica para modelos de linguagem com m√°scara, como\n",
        "    o BERT. √â utilizada em tarefas onde parte da sequ√™ncia de entrada √©\n",
        "    mascarada, e o modelo √© treinado para prever as palavras mascaradas\n",
        "    com base no contexto circundante.\n",
        "\n",
        "**ForMultipleChoice**\n",
        "\n",
        "    Projetado para tarefas de escolha m√∫ltipla, este tipo de classe √©\n",
        "    √∫til quando v√°rias op√ß√µes s√£o fornecidas e o modelo deve escolher\n",
        "    a melhor resposta com base na informa√ß√£o contida na sequ√™ncia de entrada.\n",
        "\n",
        "**ForQuestionAnswering**\n",
        "\n",
        "    Especialmente adaptado para tarefas de Perguntas e Respostas (Q&A),\n",
        "    esta classe √© projetada para localizar e fornecer respostas relevantes\n",
        "    dentro de uma sequ√™ncia de texto, dada uma pergunta.\n",
        "\n",
        "**ForSequenceClassification**\n",
        "\n",
        "    Esta classe √© usada para tarefas de classifica√ß√£o de sequ√™ncia, como\n",
        "    atribuir uma etiqueta ou categoria a uma sequ√™ncia de entrada. √â\n",
        "    comumente usado em tarefas de an√°lise de sentimento, onde o objetivo\n",
        "    √© classificar o sentimento de um texto como positivo, negativo ou neutro.\n",
        "\n",
        "**ForTokenClassification**\n",
        "\n",
        "    Projetado para tarefas de classifica√ß√£o de tokens, essa classe √© usada\n",
        "    quando √© necess√°rio atribuir uma etiqueta a cada token em uma sequ√™ncia.\n",
        "    √â comumente usado em tarefas como reconhecimento de entidades nomeadas\n",
        "    (NER), onde o objetivo √© identificar e classificar entidades espec√≠ficas\n",
        "    em um texto.Dentre outros...\n",
        "\n",
        "Dito isso:\n",
        "\n",
        "    Para nosso exemplo, precisaremos de um modelo com uma cabe√ßa\n",
        "    de classifica√ß√£o de sequ√™ncia (para ser capaz de classificar as\n",
        "    senten√ßas como positivas ou negativas). Portanto, na verdade,\n",
        "    n√£o usaremos a classe AutoModel, mas AutoModelForSequenceClassification:\n"
      ],
      "metadata": {
        "id": "tTYtcnz1lJZS"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Com o Pytorch**"
      ],
      "metadata": {
        "id": "97hTeYQReVak"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# API para o Pytorch:\n",
        "from transformers import AutoModelForSequenceClassification"
      ],
      "metadata": {
        "id": "HNL2Z62JbeNr"
      },
      "execution_count": 63,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Instanciando o modelo:\n",
        "model_torch = AutoModelForSequenceClassification.from_pretrained(checkpoint)\n",
        "\n",
        "# Realizando a infer√™ncia:\n",
        "outputs_torch = model_torch(**inputs_torch)\n",
        "print(outputs_torch)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "05XYXob_eYZr",
        "outputId": "f932b9b0-5323-4344-a1dd-3f976216e684"
      },
      "execution_count": 66,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "SequenceClassifierOutput(loss=None, logits=tensor([[-1.5607,  1.6123],\n",
            "        [ 4.1692, -3.3464]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(outputs_torch.logits.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zeUmbNHDej07",
        "outputId": "b7c1bb2d-d1aa-4b1d-af0a-d9cafe467bc0"
      },
      "execution_count": 68,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([2, 2])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Com o Tensorflow**"
      ],
      "metadata": {
        "id": "Vyo6SyP1fAYe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# API para o Tensorflow:\n",
        "from transformers import TFAutoModelForSequenceClassification"
      ],
      "metadata": {
        "id": "Y2z3SM82esZq"
      },
      "execution_count": 69,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Instanciando o modelo:\n",
        "model_tf = TFAutoModelForSequenceClassification.from_pretrained(checkpoint)\n",
        "\n",
        "# Realizando a infer√™ncia:\n",
        "outputs_tf = model_tf(inputs_tf)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "stRqVj_xfHKT",
        "outputId": "2e735c67-8ac1-4531-f870-8b8517c78a47"
      },
      "execution_count": 73,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "All PyTorch model weights were used when initializing TFDistilBertForSequenceClassification.\n",
            "\n",
            "All the weights of TFDistilBertForSequenceClassification were initialized from the PyTorch model.\n",
            "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFDistilBertForSequenceClassification for predictions without further training.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(outputs_tf)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XL4NQCbbfSlD",
        "outputId": "8cd66167-d1d9-4b54-d5e7-07b1145aba72"
      },
      "execution_count": 72,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "TFSequenceClassifierOutput(loss=None, logits=<tf.Tensor: shape=(2, 2), dtype=float32, numpy=\n",
            "array([[-1.5606961,  1.6122813],\n",
            "       [ 4.1692314, -3.3464477]], dtype=float32)>, hidden_states=None, attentions=None)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(outputs_tf.logits.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qinNZ2Kwfb1i",
        "outputId": "32ed0de2-4a95-4afc-9080-c04049a6fa51"
      },
      "execution_count": 74,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(2, 2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "    Vemos que para ambos os casos, o resultado foi o mesmo, como era\n",
        "    de se esperar. Errado seria se n√£o fosse. como temos apenas duas\n",
        "    senten√ßas e duas etiquetas, o resultado que obtemos do nosso modelo\n",
        "    tem uma forma de 2 x 2."
      ],
      "metadata": {
        "id": "3NlZbOMee2PK"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# P√≥s-processamento da sa√≠da:\n",
        "\n",
        "    Os valores que obtemos como sa√≠da do nosso modelo n√£o fazem\n",
        "    sentido necessariamente por si s√≥. Vamos dar uma olhada:\n"
      ],
      "metadata": {
        "id": "uCff9du2ffcy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Utilizando pytorch:\n",
        "print(outputs_torch.logits)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eZXnOkR-f5x7",
        "outputId": "2bd7de3f-d18b-41a2-fbb4-1392f468b5be"
      },
      "execution_count": 76,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[-1.5607,  1.6123],\n",
            "        [ 4.1692, -3.3464]], grad_fn=<AddmmBackward0>)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Utilizando Tensorflow:\n",
        "print(outputs_tf.logits)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "i63byesff-KD",
        "outputId": "53b19f4f-4f07-465f-aae4-68a5cc15cd43"
      },
      "execution_count": 77,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tf.Tensor(\n",
            "[[-1.5606961  1.6122813]\n",
            " [ 4.1692314 -3.3464477]], shape=(2, 2), dtype=float32)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "    Nosso modelo previu [-1.5607, 1.6123] para a primeira senten√ßa e\n",
        "    [4.1692, -3.3464] para a segunda. Esses n√£o s√£o probabilidades, mas\n",
        "    logitos, os escores brutos e n√£o normalizados produzidos pela √∫ltima\n",
        "    camada do modelo. Para serem convertidos em probabilidades, eles precisam\n",
        "    passar por uma camada SoftMax (todos os modelos ü§ó Transformers geram os\n",
        "    logitos, j√° que a fun√ß√£o de perda para treinamento geralmente incorpora\n",
        "    a √∫ltima fun√ß√£o de ativa√ß√£o, como o SoftMax, com a pr√≥pria fun√ß√£o de\n",
        "    perda, como entropia cruzada):"
      ],
      "metadata": {
        "id": "-OAC_zatgv7s"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Com o Pytorch**"
      ],
      "metadata": {
        "id": "yazzqwVNhDIW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Importando o Pytorch\n",
        "import torch"
      ],
      "metadata": {
        "id": "KqePZy22gDi6"
      },
      "execution_count": 79,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Aplicando a fun√ß√£o ativa√ß√£o:\n",
        "predictions_torch = torch.nn.functional.softmax(outputs_torch.logits, dim=-1)\n",
        "\n",
        "print(predictions_torch)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OxIFXBeFhGGz",
        "outputId": "673229aa-e144-4882-b803-05f18ddef548"
      },
      "execution_count": 81,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[4.0195e-02, 9.5980e-01],\n",
            "        [9.9946e-01, 5.4418e-04]], grad_fn=<SoftmaxBackward0>)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Com o Tensorflow**"
      ],
      "metadata": {
        "id": "dC58sYQghZZj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Importando o Tensorflow:\n",
        "import tensorflow as tf"
      ],
      "metadata": {
        "id": "t5-7ZMbJhQub"
      },
      "execution_count": 82,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Aplicando a fun√ß√£o ativa√ß√£o:\n",
        "predictions_tf = tf.math.softmax(outputs_tf.logits, axis=-1)\n",
        "print(predictions_tf)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ig4zLweVhf9T",
        "outputId": "e3196cf5-c490-4593-e1a3-7879c7b55951"
      },
      "execution_count": 83,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tf.Tensor(\n",
            "[[4.0195391e-02 9.5980465e-01]\n",
            " [9.9945587e-01 5.4418371e-04]], shape=(2, 2), dtype=float32)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "A importancia de importar as depend√™ncias:\n",
        "\n",
        "    A fun√ß√£o ativa√ß√£o √© parte ess√™ncial de uma rede neural que fa√ßa\n",
        "    predi√ß√µes no campo da classifica√ß√£o, que √© o nosso caso aqui, e\n",
        "    que para que seja possivel ser aplicada, precisamos utilizar um\n",
        "    m√©todo de alguma das bibliotecas. Isso √© importante de ser ressaltado\n",
        "    para enteder como fazer isso na pr√°tica.\n",
        "\n",
        "Dito isso:\n",
        "   \n",
        "    Agora podemos ver que o modelo previu [0.0402, 0.9598] para a\n",
        "    primeira senten√ßa e [0.9995, 0.0005] para a segunda. Essas s√£o\n",
        "    pontua√ß√µes de probabilidade reconhec√≠veis.\n",
        "\n",
        "    Para obter as etiquetas correspondentes a cada posi√ß√£o, podemos\n",
        "    inspecionar o atributo id2label da configura√ß√£o do modelo (mais\n",
        "    sobre isso na pr√≥xima se√ß√£o):"
      ],
      "metadata": {
        "id": "sP-7XIV0hs-I"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Com o Pytorch**"
      ],
      "metadata": {
        "id": "xFzg60u7kTC1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Pytorch:\n",
        "labels_torch = model_torch.config.id2label;labels_torch"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NL6O4QOjho-2",
        "outputId": "512264d9-59b3-4a43-a263-61756b060d77"
      },
      "execution_count": 98,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{0: 'NEGATIVE', 1: 'POSITIVE'}"
            ]
          },
          "metadata": {},
          "execution_count": 98
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def classify_labels_torch(predictions, labels):\n",
        "    \"\"\"\n",
        "    Classifica os r√≥tulos com base nas previs√µes do modelo.\n",
        "\n",
        "    Args:\n",
        "    - predictions: Tensor contendo as previs√µes do modelo ap√≥s a aplica√ß√£o da fun√ß√£o softmax.\n",
        "    - labels: Mapeamento de IDs para r√≥tulos (ex: model_torch.config.id2label).\n",
        "\n",
        "    Returns:\n",
        "    - Lista de r√≥tulos classificados para cada entrada.\n",
        "    \"\"\"\n",
        "\n",
        "    # Obt√©m o √≠ndice do r√≥tulo com a probabilidade mais alta para cada entrada.\n",
        "    predicted_indices = torch.argmax(predictions, dim=-1).numpy()\n",
        "\n",
        "    # Mapeia os √≠ndices para os r√≥tulos usando o dicion√°rio de id2label.\n",
        "    predicted_labels = [labels[idx] for idx in predicted_indices]\n",
        "\n",
        "    print(f'Temos ent√£o que para a primeira entrada a classfica√ß√£o foi {predicted_labels[0]} e para a segunda entrada temos {predicted_labels[1]}')\n",
        "\n",
        "    return predicted_labels"
      ],
      "metadata": {
        "id": "kDdjN-OfiotX"
      },
      "execution_count": 99,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "_ = classify_labels_torch(predictions_torch,labels_torch)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3ojYhahajQe4",
        "outputId": "03bb4b3c-7325-4bcc-c1b6-0d9ed28aafe6"
      },
      "execution_count": 100,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Temos ent√£o que para a primeira entrada a classfica√ß√£o foi POSITIVE e para a segunda entrada temos NEGATIVE\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Com o Tensorflow**"
      ],
      "metadata": {
        "id": "70J3235RkYdY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Tensorflow:\n",
        "labels_tf = model_tf.config.id2label;labels_tf"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4GpzxDBgiiDD",
        "outputId": "47f8bc4f-4605-451c-e99e-83294c92ddd3"
      },
      "execution_count": 101,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{0: 'NEGATIVE', 1: 'POSITIVE'}"
            ]
          },
          "metadata": {},
          "execution_count": 101
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def classify_labels_tf(predictions, labels):\n",
        "    \"\"\"\n",
        "    Classifica os r√≥tulos com base nas previs√µes do modelo.\n",
        "\n",
        "    Args:\n",
        "    - predictions: Tensor contendo as previs√µes do modelo ap√≥s a aplica√ß√£o da fun√ß√£o softmax.\n",
        "    - labels: Mapeamento de IDs para r√≥tulos (ex: model_torch.config.id2label).\n",
        "\n",
        "    Returns:\n",
        "    - Lista de r√≥tulos classificados para cada entrada.\n",
        "    \"\"\"\n",
        "\n",
        "    # Obt√©m o √≠ndice do r√≥tulo com a probabilidade mais alta para cada entrada.\n",
        "    predicted_indices = tf.argmax(predictions, axis=-1).numpy()\n",
        "\n",
        "    # Mapeia os √≠ndices para os r√≥tulos usando o dicion√°rio de id2label.\n",
        "    predicted_labels = [labels[idx] for idx in predicted_indices]\n",
        "\n",
        "    print(f'Temos ent√£o que para a primeira entrada a classifica√ß√£o foi {predicted_labels[0]} e para a segunda entrada temos {predicted_labels[1]}')\n",
        "\n",
        "    return predicted_labels"
      ],
      "metadata": {
        "id": "RS31LkkYkO_M"
      },
      "execution_count": 102,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "_ = classify_labels_tf(predictions_tf,labels_tf)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "R_vIr6QQikxs",
        "outputId": "5770d439-6333-4852-c3df-61ea88ac97f9"
      },
      "execution_count": 103,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Temos ent√£o que para a primeira entrada a classifica√ß√£o foi POSITIVE e para a segunda entrada temos NEGATIVE\n"
          ]
        }
      ]
    }
  ]
}