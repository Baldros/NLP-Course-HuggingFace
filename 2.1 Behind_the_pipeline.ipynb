{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "y9mJIvqELoh7",
        "ag34H6B7MHmh",
        "yo7OA0piT3G1",
        "5QlotA27V96R",
        "uCff9du2ffcy"
      ],
      "authorship_tag": "ABX9TyNN5oyDdrzANUiv+2RpuNMF",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Baldros/NLP-Course-HuggingFace/blob/main/2.1%20Behind_the_pipeline.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Apresentação:\n",
        "\n",
        "    Aqui aprenderemos um pouco sobre a construção do método Pipeline da\n",
        "    biblioteca transformers. O curso apresenta a explicação para o pytorch\n",
        "    e para o tensorflow. Aqui constará a explicação para ambas as bibliotecas.\n",
        "\n",
        "    Nesse inicio, a diferência é tão sutil, que dá para seguir de uma forma\n",
        "    geral para ambos os casos até o final desse notebook."
      ],
      "metadata": {
        "id": "kSe9wJAcKeuT"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Por de trás do pipeline:\n",
        "\n",
        "    Vamos começar com um exemplo completo, ando uma\n",
        "    olhada no que aconteceu nos bastidores quando\n",
        "    executamos o seguinte código no Capítulo 1:"
      ],
      "metadata": {
        "id": "y9mJIvqELoh7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Importando a API pipeline:\n",
        "from transformers import pipeline"
      ],
      "metadata": {
        "id": "PtNg5_d6Kqks"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Exemplo utilizado:\n",
        "classifier = pipeline(\"sentiment-analysis\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mtagKhYNMDC4",
        "outputId": "95fdc1eb-6a13-4265-dd83-b44984bbe837"
      },
      "execution_count": 105,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "No model was supplied, defaulted to distilbert/distilbert-base-uncased-finetuned-sst-2-english and revision af0f99b (https://huggingface.co/distilbert/distilbert-base-uncased-finetuned-sst-2-english).\n",
            "Using a pipeline without specifying a model name and revision in production is not recommended.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "classifier(\n",
        "    [\n",
        "        \"I've been waiting for a HuggingFace course my whole life.\",\n",
        "        \"I hate this so much!\",\n",
        "    ]\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4Z73wASkkzh_",
        "outputId": "ecd5696d-3d63-4e01-f8ba-8d82316c4608"
      },
      "execution_count": 106,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[{'label': 'POSITIVE', 'score': 0.9598048329353333},\n",
              " {'label': 'NEGATIVE', 'score': 0.9994558691978455}]"
            ]
          },
          "metadata": {},
          "execution_count": 106
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "    Como já vimos no Capítulo 1, esse pipeline agrupa as três\n",
        "    principais etapas: pré-processamento, passagem das entradas\n",
        "    pelo modelo e pós-processamento. No contexto de NLP, podemos\n",
        "    renomear essas três etapas como:\n",
        "    \n",
        "![image.png](data:image/png;base64,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)"
      ],
      "metadata": {
        "id": "TRPwENNRMONj"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Pré-processamento com um tokenizador:\n",
        "\n",
        "    Assim como outras redes neurais, os modelos Transformer não podem\n",
        "    processar texto bruto diretamente (não podemos esquecer que computadores\n",
        "    são máquinas de fazer conta né). Portanto, a primeira etapa de nosso\n",
        "    pipeline é converter as entradas de texto em números que o modelo\n",
        "    possa entender. Para fazer isso, usamos um tokenizador, que será\n",
        "    responsável por:\n",
        "\n",
        "    1. Dividir a entrada em palavras, subpalavras ou símbolos (como pontuação) chamados de tokens;\n",
        "    2. Mapear cada token para um inteiro;\n",
        "    3. Adicionar entradas adicionais que podem ser úteis para o modelo.\n",
        "\n",
        "    Todo esse pré-processamento precisa ser feito exatamente da mesma\n",
        "    maneira que durante o pré-treinamento do modelo. Portanto, primeiro\n",
        "    precisamos baixar essas informações do Model Hub. Para fazer isso,\n",
        "    usamos a classe AutoTokenizer e seu método from_pretrained(). Usando\n",
        "    o nome do ponto de verificação (checkpoint) do nosso modelo, ele\n",
        "    buscará automaticamente os dados associados ao tokenizador do modelo\n",
        "    e fará cache deles (portanto, só será baixado na primeira vez que você\n",
        "    executar o código abaixo).\n",
        "\n",
        "Nota:\n",
        "\n",
        "    Apesar de não ficar bem explicado, eu gosto de ressaltar que tokenizadores\n",
        "    também são redes neurais, basicamente, tudo aqui é rede neural, tanto\n",
        "    o modelo em si, quanto os outros processos que alimentam o modelo. Eu\n",
        "    gosto de ressaltar esse ponto, porque, principalmente para os iniciantes,\n",
        "    isso não fica muito claro, essa parte passa-se meio batido.\n",
        "\n",
        "Dito isso:\n",
        "\n",
        "    Como o ponto de verificação padrão do pipeline de análise de sentimento\n",
        "    é distilbert-base-uncased-finetuned-sst-2-english, executamos o seguinte:\n",
        "\n",
        "Modelo: ttps://huggingface.co/distilbert/distilbert-base-uncased-finetuned-sst-2-english\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "ag34H6B7MHmh"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Nota:\n",
        "\n",
        "    A partir desse ponto começaram a aparecer as diferenças entre\n",
        "    se utilizar Pytorch ou Tensorflow, como dito na aprensentação,\n",
        "    irei elaborar estudar aqui as duas possibilidade. É bem simples,\n",
        "    no nivel que estamos estudando, não há muita diferença."
      ],
      "metadata": {
        "id": "fuBObDxbPQKI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Com o Pytorch**"
      ],
      "metadata": {
        "id": "Wfn9xBn-PkXC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Importando Tokenizador:\n",
        "from transformers import AutoTokenizer"
      ],
      "metadata": {
        "id": "gCUgz5m0Pta5"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Definindo o modelo a ser utilizado - A arquitetura e os pesos:\n",
        "checkpoint = \"distilbert-base-uncased-finetuned-sst-2-english\""
      ],
      "metadata": {
        "id": "7oFWNQbeVsk4"
      },
      "execution_count": 48,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Instanciando o modelo:\n",
        "tokenizer = AutoTokenizer.from_pretrained(checkpoint)"
      ],
      "metadata": {
        "id": "4ogzWfckN46L"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "    Depois de obtermos o tokenizador, podemos passar diretamente nossas\n",
        "    sentenças para ele e receberemos de volta um dicionário pronto para\n",
        "    alimentar nosso modelo! A única coisa que resta fazer é converter a\n",
        "    lista de IDs de entrada em tensores.\n",
        "\n",
        "    Para especificar o tipo de tensores que queremos receber de volta\n",
        "    (PyTorch, TensorFlow ou NumPy puro), usamos o argumento return_tensors:"
      ],
      "metadata": {
        "id": "RXCX1R4OP6tp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Tokenizando:\n",
        "raw_inputs = [\n",
        "    \"I've been waiting for a HuggingFace course my whole life.\",\n",
        "    \"I hate this so much!\",\n",
        "]\n",
        "# Realizando a inferência\n",
        "inputs_torch = tokenizer(raw_inputs, padding=True, truncation=True, return_tensors=\"pt\") #pt == Pytorch"
      ],
      "metadata": {
        "id": "zxgtTMJEP0YI"
      },
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Como o retorno é um dicionário:\n",
        "print(inputs_torch.keys())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vb--geG0Qseg",
        "outputId": "5e041867-7060-492d-8aa3-f47a11dfc8d0"
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "dict_keys(['input_ids', 'attention_mask'])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Retornando os elementos do Dicionário:\n",
        "print(inputs_torch['input_ids'])\n",
        "print(inputs_torch['attention_mask'])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KuR_eefcQxwL",
        "outputId": "0c3827ab-5559-4e79-b52f-a999e7e1274e"
      },
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[  101,  1045,  1005,  2310,  2042,  3403,  2005,  1037, 17662, 12172,\n",
            "          2607,  2026,  2878,  2166,  1012,   102],\n",
            "        [  101,  1045,  5223,  2023,  2061,  2172,   999,   102,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0]])\n",
            "tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
            "        [1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Realizando a inferência**\n",
        "\n",
        "    Realizar a inferência do modelo refere-se ao processo de usar um\n",
        "    modelo treinado para fazer previsões ou gerar saídas com base em\n",
        "    dados de entrada. Essa é uma nomenclatura específica para chamar\n",
        "    as predições feitas por modelos pré-treinados.\n",
        "    \n",
        "    Essa linguagem serve para qualquer tipo de biblioteca que se esteja\n",
        "    utilizando como suporte para a API do transformer."
      ],
      "metadata": {
        "id": "vHN5ZVPKXTTb"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Com o Tensorflow**"
      ],
      "metadata": {
        "id": "tQmHIQuaSUi6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "raw_inputs = [\n",
        "    \"I've been waiting for a HuggingFace course my whole life.\",\n",
        "    \"I hate this so much!\",\n",
        "]\n",
        "\n",
        "# Realizando a inferência\n",
        "inputs_tf = tokenizer(raw_inputs, padding=True, truncation=True, return_tensors=\"tf\") # tf == tensorflow"
      ],
      "metadata": {
        "id": "S6jUTiaFSXJs"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Como o retorno é um dicionário:\n",
        "print(inputs_tf.keys())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "s_kX8j_NSrGM",
        "outputId": "1a9e186a-772f-45e2-d067-9be196b7714b"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "dict_keys(['input_ids', 'attention_mask'])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Retornando os elementos do Dicionário:\n",
        "print(inputs_tf['input_ids'])\n",
        "print(inputs_tf['attention_mask'])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c17Qr5bgStJC",
        "outputId": "77572c0b-8395-4728-a33f-0b054d4b4d3d"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tf.Tensor(\n",
            "[[  101  1045  1005  2310  2042  3403  2005  1037 17662 12172  2607  2026\n",
            "   2878  2166  1012   102]\n",
            " [  101  1045  5223  2023  2061  2172   999   102     0     0     0     0\n",
            "      0     0     0     0]], shape=(2, 16), dtype=int32)\n",
            "tf.Tensor(\n",
            "[[1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]\n",
            " [1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0]], shape=(2, 16), dtype=int32)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Onde, para ambos os casos:**\n",
        "\n",
        "    1. 'input_ids': São os identificadores numéricos únicos associados\n",
        "    a cada token no vocabulário do modelo. Cada número inteiro representa\n",
        "    um token específico. No exemplo fornecido, os números epresentam os\n",
        "    tokens em inglês correspondentes às palavras nas frases originais.\n",
        "    O token especial [CLS] (101) é adicionado no início de cada sequência,\n",
        "    e [SEP] (102) é adicionado ao final. Tokens adicionais são preenchidos\n",
        "    com zeros à direita para alinhar as sequências, devido ao parâmetro\n",
        "    padding=True.\n",
        "\n",
        "    2. 'attention_mask': São os elementos da sequência são tokens reais\n",
        "    e quais são tokens de preenchimento. Um valor de 1 indica que o token\n",
        "    na posição correspondente em 'input_ids' é um token real, enquanto um\n",
        "    valor de 0 indica que é um token de preenchimento. Isso é útil para\n",
        "    garantir que o modelo leve em consideração apenas os tokens relevantes\n",
        "    durante o processamento."
      ],
      "metadata": {
        "id": "ebOzPaVVRRpM"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "    Note que a diferença de se utilizar pytorch para tensorflow\n",
        "    é realmente muito pouca. O tensorflow da um pouquinho mais\n",
        "    de informação mais é bobagem."
      ],
      "metadata": {
        "id": "W8xM-t1nS_Nt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Tensorflow:\n",
        "inputs_tf"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hzo9FNkbS87W",
        "outputId": "85abd657-9384-4d1f-db68-2662df970f76"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'input_ids': <tf.Tensor: shape=(2, 16), dtype=int32, numpy=\n",
              "array([[  101,  1045,  1005,  2310,  2042,  3403,  2005,  1037, 17662,\n",
              "        12172,  2607,  2026,  2878,  2166,  1012,   102],\n",
              "       [  101,  1045,  5223,  2023,  2061,  2172,   999,   102,     0,\n",
              "            0,     0,     0,     0,     0,     0,     0]], dtype=int32)>, 'attention_mask': <tf.Tensor: shape=(2, 16), dtype=int32, numpy=\n",
              "array([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
              "       [1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0]], dtype=int32)>}"
            ]
          },
          "metadata": {},
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Pytorch\n",
        "inputs_torch"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3UkRBGZwQg05",
        "outputId": "cde09a52-a36d-481e-d709-2da55240d27f"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'input_ids': tensor([[  101,  1045,  1005,  2310,  2042,  3403,  2005,  1037, 17662, 12172,\n",
              "          2607,  2026,  2878,  2166,  1012,   102],\n",
              "        [  101,  1045,  5223,  2023,  2061,  2172,   999,   102,     0,     0,\n",
              "             0,     0,     0,     0,     0,     0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
              "        [1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0]])}"
            ]
          },
          "metadata": {},
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Tensores**\n",
        "\n",
        "    Você pode usar 🤗 Transformers sem se preocupar com qual framework de\n",
        "    ML está sendo usado como backend; pode ser PyTorch, TensorFlow ou Flax\n",
        "    para alguns modelos. No entanto, modelos Transformer aceitam apenas\n",
        "    tensores como entrada. Se esta for a primeira vez que você ouve falar\n",
        "    sobre tensores, pode pensar neles como arrays NumPy. Um array NumPy pode\n",
        "    ser um escalar (0D), um vetor (1D), uma matriz (2D) ou ter mais dimensões.\n",
        "    como tensores (3D). Efetivamente, é um tensor; os tensores de outros\n",
        "    frameworks de ML se comportam de maneira semelhante e geralmente são tão\n",
        "    simples de instanciar quanto arrays NumPy.\n",
        "\n",
        "Nota:\n",
        "\n",
        "    A ideia de tensor da Matemática é um pouco diferente da ideia de tensor\n",
        "    de Machine Learning, não vou aqui abordar muito esse tema, até porque\n",
        "    nem eu entendo exatamente bem a diferença entre ambos. Basta dizer que\n",
        "    aqui estamos nos baseando na definição de tensores utilizadas em ML."
      ],
      "metadata": {
        "id": "hjUjmV3PTZAW"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Passando pelo modelo\n",
        "\n",
        "    Aqui de fato a aparecer umas diferenças mais profundas entre\n",
        "    a utilização de bibliotecas diferentes de ML. De fato aqui,\n",
        "    até o modelo é diferente. Dito isso, Podemos baixar nosso modelo\n",
        "    pré-treinado da mesma forma que fizemos com nosso tokenizador.\n",
        "    🤗 Transformers fornece uma classe AutoModel/TFAutoModel que\n",
        "    também possui um método from_pretrained:"
      ],
      "metadata": {
        "id": "yo7OA0piT3G1"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Com o Pytorch**"
      ],
      "metadata": {
        "id": "gYdfYC4IUScE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# API para o Pytorch:\n",
        "from transformers import AutoModel"
      ],
      "metadata": {
        "id": "3fxYtG9eRAhY"
      },
      "execution_count": 52,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Instanciando modelo:\n",
        "model_torch = AutoModel.from_pretrained(checkpoint)"
      ],
      "metadata": {
        "id": "upv1V1TJUY7a"
      },
      "execution_count": 57,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Com o Tensorflow**"
      ],
      "metadata": {
        "id": "EkvPtQMlVadw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# API para o Tensorflow:\n",
        "from transformers import TFAutoModel"
      ],
      "metadata": {
        "id": "3kHKOB6yVPcz"
      },
      "execution_count": 54,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Instanciando o modelo:\n",
        "model_tf = TFAutoModel.from_pretrained(checkpoint)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4BhCzqUpVmG8",
        "outputId": "282e64b4-1e26-46b0-bf37-df0b13f767e2"
      },
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of the PyTorch model were not used when initializing the TF 2.0 model TFDistilBertModel: ['pre_classifier.weight', 'classifier.bias', 'classifier.weight', 'pre_classifier.bias']\n",
            "- This IS expected if you are initializing TFDistilBertModel from a PyTorch model trained on another task or with another architecture (e.g. initializing a TFBertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing TFDistilBertModel from a PyTorch model that you expect to be exactly identical (e.g. initializing a TFBertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "All the weights of TFDistilBertModel were initialized from the PyTorch model.\n",
            "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFDistilBertModel for predictions without further training.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Utilizando o mesmo conjunto de pesos:\n",
        "\n",
        "    Neste trecho de código, baixamos o mesmo ponto de verificação (checkpoint)\n",
        "    ou seja, o nosso conjunto de pesos que usamos em nosso pipeline anterior\n",
        "    (ele deveria ter sido armazenado em cache) e instanciamos um modelo com ele.\n",
        "\n",
        "    Esta arquitetura contém apenas o módulo Transformer base: dadas algumas\n",
        "    entradas, ela gera o que chamaremos de estados ocultos (hidden states),\n",
        "    também conhecidos como características (features). Para cada entrada do\n",
        "    modelo, recuperaremos um vetor de alta dimensão representando a compreensão\n",
        "    contextual dessa entrada pelo modelo Transformer.\n",
        "\n",
        "    Se isso não fizer sentido, não se preocupe. Explicaremos tudo mais tarde.\n",
        "\n",
        "    Embora esses estados ocultos possam ser úteis por si só, geralmente são\n",
        "    entradas para outra parte do modelo, conhecida como a cabeça (head).\n",
        "    No Capítulo 1, as diferentes tarefas poderiam ter sido realizadas com\n",
        "    a mesma arquitetura, mas cada uma dessas tarefas terá uma cabeça (head)\n",
        "    diferente associada.\n",
        "    \n",
        "Um vetor de alta dimensão?\n",
        "\n",
        "    O vetor gerado pelo módulo Transformer geralmente é grande. Geralmente,\n",
        "    ele tem três dimensões, por isso ele é e precisa ser um tensor:\n",
        "\n",
        "    1. Tamanho do lote (batch size): O número de sequências processadas\n",
        "    de uma vez (2 em nosso exemplo);\n",
        "    2. Comprimento da sequência (sequence length): O comprimento da\n",
        "    representação numérica da sequência (16 em nosso exemplo);\n",
        "    3. Tamanho oculto (hidden size): A dimensão do vetor de cada entrada\n",
        "    do modelo.\n",
        "\n",
        "    É chamado de \"alta dimensão\" por causa do último valor. O tamanho\n",
        "    oculto pode ser muito grande (768 é comum para modelos menores, e\n",
        "    em modelos maiores isso pode chegar a 3072 ou mais).\n",
        "\n",
        "    Podemos ver isso se alimentarmos as entradas que pré-processamos em\n",
        "    nosso modelo:"
      ],
      "metadata": {
        "id": "HAEuoAZcX39L"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Com o Pytorch**"
      ],
      "metadata": {
        "id": "T1oEmeX5Zoxy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Realizando a inferência do modelo\n",
        "outputs_torch = model_torch(**inputs_torch)\n",
        "print(outputs_torch.last_hidden_state.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "W12Pe9cEUeQB",
        "outputId": "2a726af5-a8fb-43a9-d23d-9c2c9e39fdb9"
      },
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([2, 16, 768])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "    Note que aqui tem uma diferença... Porque no pytorch entra\n",
        "    esse elemento ** no parâmetro. O uso do duplo asterisco (**)\n",
        "    em Python é conhecido como \"desempacotamento de dicionário\" ou\n",
        "    \"argumentos de palavras-chave arbitrários\". Ele é usado para\n",
        "    passar um dicionário como argumentos de palavra-chave para uma\n",
        "    função."
      ],
      "metadata": {
        "id": "9shbGnmIWBJy"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Com o Tensorflow**"
      ],
      "metadata": {
        "id": "sUVnt8_UZq5Z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Realizando a inferência do modelo\n",
        "outputs_tf = model_tf(inputs_tf)\n",
        "print(outputs_tf.last_hidden_state.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ANLHbA2VVorx",
        "outputId": "19477455-2487-49ff-c113-3ee9e5e60cad"
      },
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(2, 16, 768)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "    Note que no caso do tensorflow, não há a necessidade de\n",
        "    se \"desempacotar o dicionário\"."
      ],
      "metadata": {
        "id": "2BaI1MdlWfsf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Nota:\n",
        "\n",
        "    Observe que as saídas dos modelos 🤗 Transformers se comportam como\n",
        "    namedtuples ou dicionários. Você pode acessar os elementos por atributos\n",
        "    (como fizemos) ou por chave (outputs[\"last_hidden_state\"]), ou até mesmo\n",
        "    por índice se souber exatamente onde está o que está procurando (outputs[0])."
      ],
      "metadata": {
        "id": "qXCxZxfTbAsk"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Model Heads: Entendendo os números\n",
        "\n",
        "    As cabeças do modelo (Model Heads) recebem o vetor de alta dimensão\n",
        "    dos estados ocultos como entrada e os projetam em uma dimensão diferente.\n",
        "    Geralmente, são compostas por uma ou algumas camadas lineares:\n",
        "\n",
        "![image.png](data:image/png;base64,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)"
      ],
      "metadata": {
        "id": "5QlotA27V96R"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "    A saída do modelo Transformer é enviada diretamente para a cabeça do\n",
        "    modelo (head) para ser processada.\n",
        "\n",
        "    Neste diagrama, o modelo é representado por sua camada de embeddings e\n",
        "    pelas camadas subsequentes. A camada de embeddings converte cada ID de\n",
        "    entrada na entrada tokenizada em um vetor que representa o token associado.\n",
        "    As camadas subsequentes manipulam esses vetores usando o mecanismo de\n",
        "    atenção (self-attention) para produzir a representação final das sentenças.\n",
        "\n",
        "    Existem muitas arquiteturas diferentes disponíveis em 🤗 Transformers,\n",
        "    cada uma projetada para enfrentar uma tarefa específica. Aqui está uma\n",
        "    lista não exaustiva:\n",
        "\n",
        "**Model (recupera os hidden states)**\n",
        "\n",
        "    Esta classe é geralmente utilizada para recuperar os estados ocultos\n",
        "    de um modelo Transformer, ou seja, as representações intermediárias\n",
        "    geradas durante o processamento de uma sequência de entrada. É útil\n",
        "    para análises mais avançadas e tarefas personalizadas que podem\n",
        "    exigir acesso a esses estados.\n",
        "\n",
        "**ForCausalLM**\n",
        "\n",
        "    Projetado para modelos de linguagem causais, este tipo de classe é\n",
        "    usado para tarefas em que a predição de uma palavra depende apenas\n",
        "    das palavras anteriores na sequência. Geralmente, é útil em geração\n",
        "    de texto onde a ordem das palavras é crucial.\n",
        "\n",
        "**ForMaskedLM**\n",
        "\n",
        "    Essa classe é específica para modelos de linguagem com máscara, como\n",
        "    o BERT. É utilizada em tarefas onde parte da sequência de entrada é\n",
        "    mascarada, e o modelo é treinado para prever as palavras mascaradas\n",
        "    com base no contexto circundante.\n",
        "\n",
        "**ForMultipleChoice**\n",
        "\n",
        "    Projetado para tarefas de escolha múltipla, este tipo de classe é\n",
        "    útil quando várias opções são fornecidas e o modelo deve escolher\n",
        "    a melhor resposta com base na informação contida na sequência de entrada.\n",
        "\n",
        "**ForQuestionAnswering**\n",
        "\n",
        "    Especialmente adaptado para tarefas de Perguntas e Respostas (Q&A),\n",
        "    esta classe é projetada para localizar e fornecer respostas relevantes\n",
        "    dentro de uma sequência de texto, dada uma pergunta.\n",
        "\n",
        "**ForSequenceClassification**\n",
        "\n",
        "    Esta classe é usada para tarefas de classificação de sequência, como\n",
        "    atribuir uma etiqueta ou categoria a uma sequência de entrada. É\n",
        "    comumente usado em tarefas de análise de sentimento, onde o objetivo\n",
        "    é classificar o sentimento de um texto como positivo, negativo ou neutro.\n",
        "\n",
        "**ForTokenClassification**\n",
        "\n",
        "    Projetado para tarefas de classificação de tokens, essa classe é usada\n",
        "    quando é necessário atribuir uma etiqueta a cada token em uma sequência.\n",
        "    É comumente usado em tarefas como reconhecimento de entidades nomeadas\n",
        "    (NER), onde o objetivo é identificar e classificar entidades específicas\n",
        "    em um texto.Dentre outros...\n",
        "\n",
        "Dito isso:\n",
        "\n",
        "    Para nosso exemplo, precisaremos de um modelo com uma cabeça\n",
        "    de classificação de sequência (para ser capaz de classificar as\n",
        "    sentenças como positivas ou negativas). Portanto, na verdade,\n",
        "    não usaremos a classe AutoModel, mas AutoModelForSequenceClassification:\n"
      ],
      "metadata": {
        "id": "tTYtcnz1lJZS"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Com o Pytorch**"
      ],
      "metadata": {
        "id": "97hTeYQReVak"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# API para o Pytorch:\n",
        "from transformers import AutoModelForSequenceClassification"
      ],
      "metadata": {
        "id": "HNL2Z62JbeNr"
      },
      "execution_count": 63,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Instanciando o modelo:\n",
        "model_torch = AutoModelForSequenceClassification.from_pretrained(checkpoint)\n",
        "\n",
        "# Realizando a inferência:\n",
        "outputs_torch = model_torch(**inputs_torch)\n",
        "print(outputs_torch)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "05XYXob_eYZr",
        "outputId": "f932b9b0-5323-4344-a1dd-3f976216e684"
      },
      "execution_count": 66,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "SequenceClassifierOutput(loss=None, logits=tensor([[-1.5607,  1.6123],\n",
            "        [ 4.1692, -3.3464]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(outputs_torch.logits.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zeUmbNHDej07",
        "outputId": "b7c1bb2d-d1aa-4b1d-af0a-d9cafe467bc0"
      },
      "execution_count": 68,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([2, 2])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Com o Tensorflow**"
      ],
      "metadata": {
        "id": "Vyo6SyP1fAYe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# API para o Tensorflow:\n",
        "from transformers import TFAutoModelForSequenceClassification"
      ],
      "metadata": {
        "id": "Y2z3SM82esZq"
      },
      "execution_count": 69,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Instanciando o modelo:\n",
        "model_tf = TFAutoModelForSequenceClassification.from_pretrained(checkpoint)\n",
        "\n",
        "# Realizando a inferência:\n",
        "outputs_tf = model_tf(inputs_tf)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "stRqVj_xfHKT",
        "outputId": "2e735c67-8ac1-4531-f870-8b8517c78a47"
      },
      "execution_count": 73,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "All PyTorch model weights were used when initializing TFDistilBertForSequenceClassification.\n",
            "\n",
            "All the weights of TFDistilBertForSequenceClassification were initialized from the PyTorch model.\n",
            "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFDistilBertForSequenceClassification for predictions without further training.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(outputs_tf)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XL4NQCbbfSlD",
        "outputId": "8cd66167-d1d9-4b54-d5e7-07b1145aba72"
      },
      "execution_count": 72,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "TFSequenceClassifierOutput(loss=None, logits=<tf.Tensor: shape=(2, 2), dtype=float32, numpy=\n",
            "array([[-1.5606961,  1.6122813],\n",
            "       [ 4.1692314, -3.3464477]], dtype=float32)>, hidden_states=None, attentions=None)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(outputs_tf.logits.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qinNZ2Kwfb1i",
        "outputId": "32ed0de2-4a95-4afc-9080-c04049a6fa51"
      },
      "execution_count": 74,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(2, 2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "    Vemos que para ambos os casos, o resultado foi o mesmo, como era\n",
        "    de se esperar. Errado seria se não fosse. como temos apenas duas\n",
        "    sentenças e duas etiquetas, o resultado que obtemos do nosso modelo\n",
        "    tem uma forma de 2 x 2."
      ],
      "metadata": {
        "id": "3NlZbOMee2PK"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Pós-processamento da saída:\n",
        "\n",
        "    Os valores que obtemos como saída do nosso modelo não fazem\n",
        "    sentido necessariamente por si só. Vamos dar uma olhada:\n"
      ],
      "metadata": {
        "id": "uCff9du2ffcy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Utilizando pytorch:\n",
        "print(outputs_torch.logits)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eZXnOkR-f5x7",
        "outputId": "2bd7de3f-d18b-41a2-fbb4-1392f468b5be"
      },
      "execution_count": 76,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[-1.5607,  1.6123],\n",
            "        [ 4.1692, -3.3464]], grad_fn=<AddmmBackward0>)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Utilizando Tensorflow:\n",
        "print(outputs_tf.logits)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "i63byesff-KD",
        "outputId": "53b19f4f-4f07-465f-aae4-68a5cc15cd43"
      },
      "execution_count": 77,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tf.Tensor(\n",
            "[[-1.5606961  1.6122813]\n",
            " [ 4.1692314 -3.3464477]], shape=(2, 2), dtype=float32)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "    Nosso modelo previu [-1.5607, 1.6123] para a primeira sentença e\n",
        "    [4.1692, -3.3464] para a segunda. Esses não são probabilidades, mas\n",
        "    logitos, os escores brutos e não normalizados produzidos pela última\n",
        "    camada do modelo. Para serem convertidos em probabilidades, eles precisam\n",
        "    passar por uma camada SoftMax (todos os modelos 🤗 Transformers geram os\n",
        "    logitos, já que a função de perda para treinamento geralmente incorpora\n",
        "    a última função de ativação, como o SoftMax, com a própria função de\n",
        "    perda, como entropia cruzada):"
      ],
      "metadata": {
        "id": "-OAC_zatgv7s"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Com o Pytorch**"
      ],
      "metadata": {
        "id": "yazzqwVNhDIW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Importando o Pytorch\n",
        "import torch"
      ],
      "metadata": {
        "id": "KqePZy22gDi6"
      },
      "execution_count": 79,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Aplicando a função ativação:\n",
        "predictions_torch = torch.nn.functional.softmax(outputs_torch.logits, dim=-1)\n",
        "\n",
        "print(predictions_torch)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OxIFXBeFhGGz",
        "outputId": "673229aa-e144-4882-b803-05f18ddef548"
      },
      "execution_count": 81,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[4.0195e-02, 9.5980e-01],\n",
            "        [9.9946e-01, 5.4418e-04]], grad_fn=<SoftmaxBackward0>)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Com o Tensorflow**"
      ],
      "metadata": {
        "id": "dC58sYQghZZj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Importando o Tensorflow:\n",
        "import tensorflow as tf"
      ],
      "metadata": {
        "id": "t5-7ZMbJhQub"
      },
      "execution_count": 82,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Aplicando a função ativação:\n",
        "predictions_tf = tf.math.softmax(outputs_tf.logits, axis=-1)\n",
        "print(predictions_tf)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ig4zLweVhf9T",
        "outputId": "e3196cf5-c490-4593-e1a3-7879c7b55951"
      },
      "execution_count": 83,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tf.Tensor(\n",
            "[[4.0195391e-02 9.5980465e-01]\n",
            " [9.9945587e-01 5.4418371e-04]], shape=(2, 2), dtype=float32)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "A importancia de importar as dependências:\n",
        "\n",
        "    A função ativação é parte essêncial de uma rede neural que faça\n",
        "    predições no campo da classificação, que é o nosso caso aqui, e\n",
        "    que para que seja possivel ser aplicada, precisamos utilizar um\n",
        "    método de alguma das bibliotecas. Isso é importante de ser ressaltado\n",
        "    para enteder como fazer isso na prática.\n",
        "\n",
        "Dito isso:\n",
        "   \n",
        "    Agora podemos ver que o modelo previu [0.0402, 0.9598] para a\n",
        "    primeira sentença e [0.9995, 0.0005] para a segunda. Essas são\n",
        "    pontuações de probabilidade reconhecíveis.\n",
        "\n",
        "    Para obter as etiquetas correspondentes a cada posição, podemos\n",
        "    inspecionar o atributo id2label da configuração do modelo (mais\n",
        "    sobre isso na próxima seção):"
      ],
      "metadata": {
        "id": "sP-7XIV0hs-I"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Com o Pytorch**"
      ],
      "metadata": {
        "id": "xFzg60u7kTC1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Pytorch:\n",
        "labels_torch = model_torch.config.id2label;labels_torch"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NL6O4QOjho-2",
        "outputId": "512264d9-59b3-4a43-a263-61756b060d77"
      },
      "execution_count": 98,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{0: 'NEGATIVE', 1: 'POSITIVE'}"
            ]
          },
          "metadata": {},
          "execution_count": 98
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def classify_labels_torch(predictions, labels):\n",
        "    \"\"\"\n",
        "    Classifica os rótulos com base nas previsões do modelo.\n",
        "\n",
        "    Args:\n",
        "    - predictions: Tensor contendo as previsões do modelo após a aplicação da função softmax.\n",
        "    - labels: Mapeamento de IDs para rótulos (ex: model_torch.config.id2label).\n",
        "\n",
        "    Returns:\n",
        "    - Lista de rótulos classificados para cada entrada.\n",
        "    \"\"\"\n",
        "\n",
        "    # Obtém o índice do rótulo com a probabilidade mais alta para cada entrada.\n",
        "    predicted_indices = torch.argmax(predictions, dim=-1).numpy()\n",
        "\n",
        "    # Mapeia os índices para os rótulos usando o dicionário de id2label.\n",
        "    predicted_labels = [labels[idx] for idx in predicted_indices]\n",
        "\n",
        "    print(f'Temos então que para a primeira entrada a classficação foi {predicted_labels[0]} e para a segunda entrada temos {predicted_labels[1]}')\n",
        "\n",
        "    return predicted_labels"
      ],
      "metadata": {
        "id": "kDdjN-OfiotX"
      },
      "execution_count": 99,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "_ = classify_labels_torch(predictions_torch,labels_torch)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3ojYhahajQe4",
        "outputId": "03bb4b3c-7325-4bcc-c1b6-0d9ed28aafe6"
      },
      "execution_count": 100,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Temos então que para a primeira entrada a classficação foi POSITIVE e para a segunda entrada temos NEGATIVE\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Com o Tensorflow**"
      ],
      "metadata": {
        "id": "70J3235RkYdY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Tensorflow:\n",
        "labels_tf = model_tf.config.id2label;labels_tf"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4GpzxDBgiiDD",
        "outputId": "47f8bc4f-4605-451c-e99e-83294c92ddd3"
      },
      "execution_count": 101,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{0: 'NEGATIVE', 1: 'POSITIVE'}"
            ]
          },
          "metadata": {},
          "execution_count": 101
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def classify_labels_tf(predictions, labels):\n",
        "    \"\"\"\n",
        "    Classifica os rótulos com base nas previsões do modelo.\n",
        "\n",
        "    Args:\n",
        "    - predictions: Tensor contendo as previsões do modelo após a aplicação da função softmax.\n",
        "    - labels: Mapeamento de IDs para rótulos (ex: model_torch.config.id2label).\n",
        "\n",
        "    Returns:\n",
        "    - Lista de rótulos classificados para cada entrada.\n",
        "    \"\"\"\n",
        "\n",
        "    # Obtém o índice do rótulo com a probabilidade mais alta para cada entrada.\n",
        "    predicted_indices = tf.argmax(predictions, axis=-1).numpy()\n",
        "\n",
        "    # Mapeia os índices para os rótulos usando o dicionário de id2label.\n",
        "    predicted_labels = [labels[idx] for idx in predicted_indices]\n",
        "\n",
        "    print(f'Temos então que para a primeira entrada a classificação foi {predicted_labels[0]} e para a segunda entrada temos {predicted_labels[1]}')\n",
        "\n",
        "    return predicted_labels"
      ],
      "metadata": {
        "id": "RS31LkkYkO_M"
      },
      "execution_count": 102,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "_ = classify_labels_tf(predictions_tf,labels_tf)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "R_vIr6QQikxs",
        "outputId": "5770d439-6333-4852-c3df-61ea88ac97f9"
      },
      "execution_count": 103,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Temos então que para a primeira entrada a classificação foi POSITIVE e para a segunda entrada temos NEGATIVE\n"
          ]
        }
      ]
    }
  ]
}